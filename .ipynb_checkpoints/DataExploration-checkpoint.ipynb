{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "061c1152",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1cf4135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import scipy\n",
    "\n",
    "with open('./data/recipes_with_nutritional_info.json') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb9bc92",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "We examine our dataset to determine the most commonly used ingredients, and actions within recipe instructions. We do this so we can better inform our choices for the ingredients and actions we will consider in our Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1651b760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    }
   ],
   "source": [
    "keys = list(dataset[0].keys())\n",
    "\n",
    "ingredients = list()\n",
    "# print(dataset[0]['ingredients'])\n",
    "\n",
    "for entry in dataset:\n",
    "    ingredient_list = [item['text'].split(',')[0] for item in entry['ingredients']]\n",
    "    ingredients.extend(ingredient_list)\n",
    "    \n",
    "print(len(list(set(ingredients)))) # Get the number of unique ingredients\n",
    "\n",
    "ingredient_freq = {i: ingredients.count(i) for i in set(ingredients)}\n",
    "sorted_ingredient_freq = sorted(ingredient_freq.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b798fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = list()\n",
    "\n",
    "for item in dataset:\n",
    "    for line in item['instructions']:\n",
    "        tokens = line['text'].split(' ')\n",
    "        actions.append(tokens[0])\n",
    "        \n",
    "action_freq = {i: actions.count(i) for i in set(actions)}\n",
    "sorted_action_freq = sorted(action_freq.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdde27dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('oats', 3322), ('mustard', 3422), ('spartan', 3642), ('onions', 4224), ('vinegar', 4450), ('lemon juice', 4453), ('honey', 4922), ('vanilla extract', 5311), ('cream', 5403), ('cheese', 6002), ('nuts', 8048), ('leavening agents', 10088), ('milk', 11017), ('oil', 11499), ('water', 13908), ('wheat flour', 14076), ('butter', 15373), ('salt', 22023), ('sugars', 26248)]\n",
      "[('Sprinkle', 4138), ('Heat', 4411), ('When', 4430), ('Put', 4631), ('Cut', 4735), ('Cook', 5033), ('If', 5170), ('Let', 5886), ('Cover', 6206), ('Serve', 6466), ('Preheat', 8058), ('Pour', 9276), ('Remove', 9617), ('Combine', 9955), ('Bake', 11183), ('Mix', 11713), ('Stir', 12071), ('Place', 13947), ('In', 15337)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted_ingredient_freq[-20:-1])\n",
    "print(sorted_action_freq[-20:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49059c6d",
   "metadata": {},
   "source": [
    "## Setting up the model\n",
    "\n",
    "Looking over the data we just collected, we can make a judicious choice of what ingredients and actions we should consider for our model. Ideally, the ingredients should be very commonly used. Actions should be sensible (they shouldn't, for example, be words like 'In'). They should also ideally 'act' on more than one ingredient at a time. Our hyperedges won't be meaningful if they just consist of one-to-one connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc84d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# For now, let us just take a fixed number of the most common ingredients and actions\n",
    "NUM_INGREDIENTS = 20\n",
    "NUM_ACTIONS = 20\n",
    "\n",
    "ingredients = [item[0] for item in sorted_ingredient_freq[:-NUM_INGREDIENTS:-1]]\n",
    "actions = [item[0] for item in sorted_action_freq[:-NUM_ACTIONS:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d230299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we convert all instructions in the dataset into a format where we can extract the \n",
    "# conditional frequencies\n",
    "\n",
    "feature_space = []\n",
    "for entry in dataset:\n",
    "    recipe_instructions = []\n",
    "    \n",
    "    for line in entry['instructions']:\n",
    "        tokens = line['text'].split(' ')\n",
    "        \n",
    "        if tokens[0] not in actions:\n",
    "            continue\n",
    "        \n",
    "        features = [tokens[0]] + list(filter(lambda s: s in ingredients, tokens))\n",
    "        actions.append(tokens[0])\n",
    "        recipe_instructions.append(features)\n",
    "        \n",
    "    feature_space.append(deepcopy(recipe_instructions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2418dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "conditional_freq = {i: [] for i in actions}\n",
    "action_freq = {i: [] for i in actions}\n",
    "\n",
    "for entry in feature_space:\n",
    "    ingredient_combinations = [line[1:] for line in entry if len(line) > 1]\n",
    "    action_list = [line[0] for line in entry if len(line) != 0]\n",
    "    \n",
    "    if len(ingredient_combinations) == 0:\n",
    "        continue\n",
    "    \n",
    "    for i in range(len(entry)):\n",
    "        action_freq[entry[i][0]].append(action_list[:i+1])\n",
    "        \n",
    "        if entry[i][0] in actions:\n",
    "            up_to = min(i+1, len(ingredient_combinations)) # Sometimes there are more actions than ingredients\n",
    "            conditional_freq[entry[i][0]].extend(ingredient_combinations[:up_to])\n",
    " \n",
    "# Reduce to frequency table\n",
    "for key in conditional_freq:\n",
    "    conditional_freq[key] = {tuple(i): conditional_freq[key].count(i) for i in np.unique(conditional_freq[key])}\n",
    "    action_freq[key] = {tuple(i): action_freq[key].count(i) for i in np.unique(action_freq[key])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8ff48849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "## Save to disk since this shit takes forever to compute\n",
    "with open('data/20x20.pkl', 'wb') as f:\n",
    "    pickle.dump([conditional_freq, action_freq], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
